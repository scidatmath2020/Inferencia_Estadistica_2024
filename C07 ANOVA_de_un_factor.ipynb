{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anova de un factor\n",
    "\n",
    "## Introducción al Análisis de la varianza (analysis of variance)\n",
    "\n",
    "Algunas veces nos interesa dividir a la población en subpoblaciones utilizando **una sola característica $F$**. Cuando este es el caso, decimos que la población está **clasificada por un factor**.\n",
    "\n",
    "Digamos que nuestra característica nos ha formado $k$ subgrupos de la población. Decimos entonces que la población está dividida en $k$ niveles del factor $F$.\n",
    "\n",
    "El **ANOVA de un solo factor** es una prueba de hipótesis para saber si las medias de cierta característica $X$ de la población son iguales en cada uno de los $k$ niveles de un factor $F$, siempre que $k>2$. \n",
    "\n",
    "Es decir, si $F$ es una característica de la población que tiene $k$ valores diferentes, y $X$ es otra característica de la población, vale la pena preguntarnos si el valor promedio de $X$ en cada una de las $k$ subpoblaciones inducidas por $F$ es el mismo.\n",
    "\n",
    "\n",
    "***\n",
    "***\n",
    "**Ejemplo 1.**\n",
    "\n",
    "Relativo a la delincuencia en México, si $F$ es la característica \"entidad donde se cometió el delito\" entonces los factores de $F$ son las 32 Entidades Federativas, de modo que $k=32$, y nos podemos preguntar si el promedio de delitos cometidos a cada víctima del delito es el mismo en las 32 entidades.\n",
    "***\n",
    "***\n",
    "\n",
    "Mas concretamente, sea $X$ una característica de la población, la cual está dividida en $k\\ge 3$ subpoblaciones. Denotemos por $\\mu_1,\\mu_2,...,\\mu_k$ a la media \"poblacional\" de $X$ en cada una de las subpoblaciones. El ANOVA de un factor es la prueba de hipótesis\n",
    "$$\\left\\{\\begin{array}{l}H_0:\\mu_1=\\mu_2=...=\\mu_k\\\\H_1:\\mbox{ existen al menos dos grupos con medias poblacionales diferentes}\\end{array}\\right.$$\n",
    "\n",
    "\n",
    "En caso de no rechazar $H_1$ (es decir, que hay al menos dos grupos con medias diferentes), debemos ser capaces, además, de identificar cuáles son las parejas de grupos cuyas medias son diferentes. \n",
    "\n",
    "\n",
    "Como hemos dicho, el ANOVA de un solo factor es una prueba de hipótesis para saber si las medias de cierta característica  $X$  de la población son iguales en cada una de las $k$ clases (niveles) en que se clasifica la población de acuerdo a una característica $F$ (factor).\n",
    "\n",
    "Los supuestos para poderlo aplicar son los siguientes:\n",
    "\n",
    "* Las muestras de cada subpoblación son independientes interna y externamente.\n",
    "* Cada una de las subpoblaciones son gaussianas.\n",
    "* Todas las subpoblaciones tienen la misma varianza común $\\sigma^2$ (**homocedasticidad**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea general del ANOVA de un factor\n",
    "\n",
    "La idea general es:\n",
    "* Observar cómo varían los datos dentro de la población total (es decir, la varianza poblacional de toda la población).\n",
    "* Observar cómo varían los datos dentro de cada subpoblación (es decir, la varianza poblacional de cada grupo).\n",
    "* Observar cómo varían las medias de cada subpoblación respecto de la media global.\n",
    "\n",
    "De esta manera, **si la variabilidad total de los datos se puede explicar por la variabilidad de las medias de las subpoblaciones y la \"poca\" variabilidad dentro de cada subpoblación, tendremos evidencia suficiente para decir que las medias son diferentes**.\n",
    "\n",
    "En cristiano: si observamos que todos los datos varían mucho entre sí, pero dentro de cada subpoblación se parecen, entonces los promedios de cada subgrupo no pueden ser iguales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "**Ejemplo 2.**\n",
    "![imagenes](im014.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "**Ejemplo 3.**\n",
    "![imagenes](im015.png)\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasos del ANOVA\n",
    "\n",
    "Ahora, para aplicar un ANOVA de un factor debe cumplirse que cada subpoblación es gaussiana y todas tienen la misma varianza. Además, una vez que tenemos el resultado, debemos conocer cuáles subplobaciones tienen varianzas diferentes. \n",
    "\n",
    "Para poder realizar ANOVA de forma automática se requiere, en primer lugar, que nuestra tabla se presente en formato largo: Es decir, de la forma\n",
    "\n",
    "Característica $X$|Factor $F$\n",
    ":--:|:--:\n",
    "$X_{1}^{(1)}$|1\n",
    "$X_{2}^{(1)}$|1\n",
    "$\\vdots$|$\\vdots$\n",
    "$X_{n_1}^{(1)}$|1\n",
    "$X_{1}^{(2)}$|2\n",
    "$X_{2}^{(2)}$|2\n",
    "$\\vdots$|$\\vdots$\n",
    "$X_{n_2}^{(2)}$|2\n",
    "$\\vdots$|$\\vdots$\n",
    "$X_{1}^{(k)}$|$k$\n",
    "$X_{2}^{(k)}$|$k$\n",
    "$\\vdots$|$\\vdots$\n",
    "$X_{n_k}^{(k)}$|$k$\n",
    "\n",
    "Presentamos a continuación la serie de pasos para realizar el ANOVA de un factor. Para ello, iremos ilustrando con el siguiente ejemplo:\n",
    "\n",
    "***\n",
    "***\n",
    "**Ejemplo 1.**\n",
    "\n",
    "Supóngase que un estudio quiere comprobar si existe una diferencia significativa entre el % de bateos exitosos de los jugadores de béisbol dependiendo de la posición en la que juegan. En el caso de que exista, se quiere saber qué posiciones difieren del resto. Los datos los encuentras en [beisbol](https://github.com/scidatmath2020/Inferencia_Estadistica_2024/blob/main/data/beisbol.csv) de nuestro repositorio de data.\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "import pingouin as pg\n",
    "\n",
    "################################################################\n",
    "```\n",
    "***\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasos del ANOVA\n",
    "\n",
    "Recuerda tener tu tabla en formato largo. **A partir del Paso 2 es fundamental**.\n",
    "\n",
    "**Paso 0) Identificación de parámetros**\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "##### Tamaño de cada grupo\n",
    "tabla.groupby('columna de factores').size()\n",
    "\n",
    "#### Cálculo de la media y desviación en cada grupo\n",
    "tabla.groupby('columna de factores').agg(['mean', 'std'])\n",
    "\n",
    "#### Gráfico de cajas\n",
    "(ggplot(data=tabla) + geom_boxplot(mapping=aes(x=\"columna de factor\",y=\"columna de datos\")))\n",
    "\n",
    "#### Histogramas\n",
    "(\n",
    "    ggplot(tabla, aes(x='columna de datos')) +\n",
    "    geom_histogram(bins=15, fill='skyblue', color='black', alpha=0.7) +\n",
    "    facet_wrap('~columna de factor', ncol=2)\n",
    ")\n",
    "\n",
    "################################################################\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Paso 1) Prueba de normalidad**\n",
    "\n",
    "$p$-valor|Decisión|Significado\n",
    ":--|:--|:--\n",
    "Pequeño|Rechazar $H_0$|Hay buena probabilidad de que **NO es gaussiana**\n",
    "Grande|Rechazar $H_1$|Hay buena probabilidad de que **SÍ es gaussiana**\n",
    "\n",
    "**Recuerda que para utilizarlos en Python requieres la biblioteca ``scipy.stats`` y/o ``statsmodels``**.\n",
    "\n",
    "Prueba|Abreviatura|Tamaño de<br> muestra|Desventaja|Estadístico|**Python**\n",
    ":--|:--:|:--:|:--|:--:|:--\n",
    "Shapiro-Wilk|SW|$n \\leq 5000$|Sensible a valores repetidos y colas|W|``shapiro()``\n",
    "Kolmogorov-Smirnov|KS|$n \\leq 1000$|Requiere especificar parámetros|D|``kstest()``\n",
    "Anderson-Darling|AD|$n \\leq 5000$|Menos eficiente en muestras grandes|A|``anderson()``\n",
    "Jarque-Bera|JB|$n \\geq 20$|Menos sensible a desviaciones pequeñas|JB|``jarque_bera()``\n",
    "\n",
    "https://github.com/scidatmath2020/Inferencia_Estadistica_2024/blob/main/scripts/Pruebas%20de%20hipotesis/gaussianidad.py\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "gaussianidad = tabla.groupby('columna de factor')['columna de datos'].apply(gaussian_test)\n",
    "\n",
    "################################################################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 2) Pruebas de homocedasticidad**\n",
    "\n",
    "Existen dos tipos básicos: Levene y Bartlett. Levenne es menos sensible a falta de gaussiandad. Es decir que, si estás muy seguro de la gaussianidad de cada grupo, utilizas Bartlett. En caso contrario, utilizas Levene.\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "pg.homoscedasticity(data=tabla, dv='columna de valor', group='columna de factor', method='levene')\n",
    "\n",
    "################################################################\n",
    "```\n",
    "\n",
    "\n",
    "La decisión se toma de la siguiente manera:\n",
    "\n",
    "$p$-valor|significado\n",
    ":--|:--\n",
    "Pequeño|Hay buena probabilidad de que las varianzas no sean iguales\n",
    "Grande|Hay buena probabilidad de que las varianzas sean iguales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 3) Realización del ANOVA**\n",
    "\n",
    "En **Python** lo hacemos de la siguiente manera:\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "pg.anova(data=tabla, dv='columna de valores', between='columna de factor', detailed=True)\n",
    "\n",
    "################################################################\n",
    "```\n",
    "\n",
    "La decisión se toma de la siguiente manera:\n",
    "\n",
    "$p$-valor|significado\n",
    ":--|:--\n",
    "Pequeño|Hay buena probabilidad de que las medias no sean iguales\n",
    "Grande|Hay buena probabilidad de que las medias sean iguales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 4) Hallar las medias diferentes: Análisis post hoc**\n",
    "\n",
    "Si un ANOVA resulta significativo implica que, al menos, dos de las medias comparadas son significativamente distintas entre sí, pero no se determina cuáles. Para identificarlas, hay que comparar dos a dos las medias de todos los grupos mediante un t-test u otro test que permita comparar 2 grupos. A esto se le conoce como análisis post-hoc. Debido a la inflación del error de tipo I, cuantas más comparaciones se hagan, más aumenta la probabilidad de encontrar diferencias significativas. Por ejemplo, para un nivel de significancia  $\\alpha = 0.05$, de cada 100 comparaciones se esperan 5 significativas solo por azar.\n",
    "\n",
    "Para evitar este problema, el nivel de significancia puede ajustarse en función del número de comparaciones (corrección de significancia). Si no se hace ningún tipo de corrección se aumenta la posibilidad de falsos positivos (error tipo I) pero, si se es muy estricto con las correcciones, se pueden considerar como no significativas diferencias que realmente sí lo son (error tipo II). La necesidad de corrección o no, y de qué tipo, se ha de estudiar con detenimiento en cada caso. A continuación, se describen los principales métodos de comparación post-hoc:\n",
    "\n",
    "| **Ajuste Post Hoc** | **Descripción** | **Cuándo Utilizar**|\n",
    "|----------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Bonferroni**       | Ajuste conservador que controla el error de Tipo I al dividir el nivel de significancia $\\alpha$ entre el número de comparaciones.                                                                                                                                      | Útil cuando se realizan un número reducido de comparaciones y se desea un control estricto del error de Tipo I. Sin embargo, puede ser demasiado conservador cuando el número de comparaciones es elevado, aumentando el riesgo de errores de Tipo II (no detectar diferencias reales).                                                                                 |\n",
    "| **Holm**             | Método secuencial que ajusta los valores $p$ de manera menos conservadora que Bonferroni, aumentando la potencia estadística.                                                                                                                                           |  No suele recomendarse si se realizan más de 6 comparaciones                                                            |\n",
    "| **Tukey**            | Prueba diseñada para comparar todas las posibles parejas de medias de grupos, controlando el error de Tipo I en el conjunto de comparaciones.                                                                                                                            | Es el ajuste recomendado cuando el número de grupos a comparar es mayor de 6 y el diseño es equilibrado (mismo número de observaciones por grupo). En el caso de modelos no equilibrados el método HSD es conservativo, requiere grandes diferencias para que resulte significativo.                                                                                                                             |\n",
    "| **Games-Howell**          | Prueba diseñada para comparar todas las posibles parejas de medias de grupos, controlando el error de Tipo I en el conjunto de comparaciones.                                                                                                                        | A diferencia de la prueba de Tukey, no asume homogeneidad de varianzas ni tamaños de muestra iguales. Así, la prueba de Games-Howell puede aplicarse en situaciones donde las suposiciones de la prueba de Tukey no se cumplen. La prueba de Games-Howell y la prueba de Tukey a menudo reportarán resultados similares con datos que se asumen con varianza igual y tamaños de muestra iguales.                                                             |\n",
    "\n",
    "\n",
    "La decisión se toma de la siguiente manera: \n",
    "\n",
    "$p$-valor|significado\n",
    ":--|:--\n",
    "Pequeño|Hay buena probabilidad de que las medias no sean iguales\n",
    "Grande|Hay buena probabilidad de que las medias sean iguales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "pg.pairwise_tests(data=tabla, dv='columna de valores', between='columna de factor', padjust='bonferroni')\n",
    "pg.pairwise_tests(data=tabla, dv='columna de valores', between='columna de factor', padjust='holm')\n",
    "pg.pairwise_tukey(data=tabla, dv='columna de valores', between='columna de factor')\n",
    "pg.pairwise_gameshowell(data=dtabla, dv='columna de valores', between='columna de factor')\n",
    "\n",
    "################################################################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica.\n",
    "\n",
    "La tabla [sismos.csv](https://github.com/scidatmath2020/Inferencia_Estadistica_2024/blob/main/data/muestra_aleatoria_sismos.csv) consiste de una muestra aleatoria de tamaño 5000 de la información tomada del Servicio Sismológico Nacional de todos los sismos registrados desde el 1 de enero de 1900 hasta las 19:40pm (hora de CDMX) del 23 de diciembre de 2023. Realiza con ella un ANOVA para:\n",
    "\n",
    "1. Verificar que la magnitud promedio mensual de los sismos en México varía durante todo el año.\n",
    "\n",
    "2. Verificar que la magnitud promedio mensual de los sismos fuertes (arriba de 6.5) en México es la misma durante todo el año."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
