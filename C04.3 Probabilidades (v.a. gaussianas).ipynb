{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables aleatorias normales\n",
    "\n",
    "Las distribuciones normales, también llamadas gaussianas, fueron introducidas por Gauss en conexión con sus trabajos sobre errores de mediciones en fenómenos físicos. Pueden considerarse las distribuciones más importantes debido a varias razones:\n",
    "\n",
    "1. Muchos fenómenos aleatorios relacionados con experimentos sociales y naturales obedecen distribuciones gaussianas.\n",
    "\n",
    "2. Muchos tipos de variables aleatorias pueden ser aproximados con distribuciones gaussianas.\n",
    "\n",
    "3. A veces una variable aleatoria no es ni gaussiana ni puede aproximarse con gaussianas, pero pueden transformarse en gaussianas mediante transformaciones.\n",
    "\n",
    "4. Muchas variables aleatorias relacionadas con las gaussianas se utilizan para realizar pruebas de hipótesis.\n",
    "\n",
    "Así como todas las variables aleatorias especiales que hemos estudiado dependen de parámetros (la $p$ en las binomiales y geométricas; la $\\lambda$ en las de Poisson y exponenciales; $a$ y $b$ en las uniformes, etcétera), las gaussianas dependen de dos parámetros: $\\mu$ (su esperanza) y $\\sigma^2$ (su varianza).\n",
    "\n",
    "De esta manera, el hecho de que $X$ sea gaussiana con media $\\mu$ y varianza $\\sigma^2$ se denota por \n",
    "\n",
    "$$X\\sim\\mathrm{N}(\\mu,\\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Características\n",
    "\n",
    "Si $X\\sim\\mathrm{N}(\\mu,\\sigma^2)$, entonces \n",
    "\n",
    "$$f_X(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "y \n",
    "\n",
    "$$F_X(x)=\\int_{-\\infty}^x\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(t-\\mu)^2}{2\\sigma^2}}\\,\\mathrm{d}t$$\n",
    "\n",
    "La integral anterior no puede resolverse de manera explícita, de modo que aquí entran en juego fundamental las computadores para realizar los cálculos.\n",
    "\n",
    "Además, $E[X]=\\mu$ y $Var(X)=\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de la distribución gaussiana\n",
    "media = 2025\n",
    "varianza = 3\n",
    "desviacion_estandar = np.sqrt(varianza)\n",
    "\n",
    "# Generar muestra de tamaño 1,000,000\n",
    "muestra = pd.DataFrame({\"valores\":np.random.normal(loc=media, scale=desviacion_estandar, size=1000000)})\n",
    "\n",
    "ggplot(muestra) + geom_histogram(mapping=aes(x=\"valores\"),fill=\"blue\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observaciones\n",
    "\n",
    "Si $X$ es una variable aleatoria cualquiera (no importa si es discreta o continua, o de cualquier clase especial), se puede definir una nueva variable aleatoria $Z$ dada por $Z=\\frac{X-E[X]}{sd(X)}$. Luego, por las propiedades de esperanza y varianza tenemos: $E[Z]=0$ y $Var(Z)=1$. Al proceso de construir esta variable $Z$ a partir de una variable $X$ se le llama **estandarización**. Cuando una variable aleatoria cumple que su media es 0 y su varianza es 1, se dice que está **estandarizada**.\n",
    "\n",
    "Si $X\\sim\\mathrm{N}(\\mu,\\sigma^2)$, entonces $aX+b$ también es gaussiana; y de hecho $aX+b\\sim\\mathrm{N}(a\\mu+b,a^2\\sigma^2)$. \n",
    "\n",
    "Cuando $X$ es una gaussiana, su estandarización $Z$ es de gran interés. Por lo dicho en los párrafos previos, $Z$ también es gaussiana con media 1 y varianza 0. Cuando se tiene una variable aleatoria gaussiana estandarizada, su función de densidad $F_Z$ se denota por $\\Phi$. Esto es:\n",
    "\n",
    "$$\\Phi(z)=F_Z(z)=\\int_{-\\infty}^z\\frac{1}{\\sqrt{2\\pi}}e^{-t^2/2}\\,\\mathrm{d}t$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinaciones lineales\n",
    "\n",
    "Supongamos que $X_1$, $X_2$,..., $X_n$ son variables aleatorias arbitrarias. Se dice que son **variables aleatorias independientes** si \n",
    "\n",
    "$$P(a_1<X_1\\le b_1\\mbox{ y }a_2<X_2\\le b_2\\mbox{ y }...\\mbox{ y }a_n<X_n\\le b_n)=P(a_1<X_1\\le b_1)P(a_2<X_2\\le b_2)...P(a_n<X_n\\le b_n)$$\n",
    "\n",
    "Esto significa que los valores que pueda tomar cualquiera de ellas no dependen de los valores que puedan tomar las otras.\n",
    "\n",
    "Dicho esto, las gaussianas tienen una propiedad que, matemáticamente, las hacen las distribuciones más importantes de todas:\n",
    "\n",
    "Si $X_1,X_2,...,X_n$ son gaussianas independientes con $X_i\\sim\\mathrm{N}(\\mu_i,\\sigma^2_i)$, entonces\n",
    "\n",
    "$$X_1+X_2+...+X_n\\sim\\mathrm{N}(\\mu_1+\\mu_2+...+\\mu_n,\\sigma_1^2+\\sigma^2_2+...+\\sigma_n^2)$$ y $$\\frac{X_1+X_2+...+X_n}{n}\\sim\\mathrm{N}\\left(\\frac{\\mu_1+\\mu_2+...+\\mu_n}{n},\\frac{\\sigma_1^2+\\sigma^2_2+...+\\sigma_n^2}{n^2}\\right)$$\n",
    "\n",
    "En particular, si $\\mu_i=\\mu$ y $\\sigma^2_i=\\sigma^2$ (es decir, todas tienen la misma media y la misma varianza), entonces\n",
    "\n",
    "$$X_1+X_2+...+X_n\\sim\\mathrm{N}(n\\mu,n\\sigma^2)$$ y $$\\frac{X_1+X_2+...+X_n}{n}\\sim\\mathrm{N}\\left(\\mu,\\frac{\\sigma^2}{n}\\right)$$\n",
    "\n",
    "Por ejemplo, supongamos que tienes una población de la cual vas a tomar una muestra de tamaño $n$ y quieres medir una característica $X$ de esa población, la cual sabes que es una v.a. gaussiana. Entonces el valor promedio de la característica $X$ vuelve a ser una gaussiana con media igual a la media poblacional y varianza igual a la varianza poblacional partido por el tamaño de la muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables aleatorias relacionadas con la gaussiana\n",
    "\n",
    "Existen algunos tipos de distribuciones continuas relacionadas con las gaussianas que son de suma importancia en Estadística. Sin adelantarnos, el Teorema del Límite central (que veremos al final de este capítulo) es la clave de la gran mayoría de los análisis estadísticos, además del hecho de que las combinaciones lineales de gaussianas independientes vuelven a ser gaussianas.\n",
    "\n",
    "De esta manera, en la práctica, *casi siempre* podemos dar argumentos matemáticos que justifican la suposición de modelos gaussianos en nuestros fenómenos; sin embargo, como no todo puede ser felicidad, se debe pagar un cierto precio por hacer esa suposición. \n",
    "\n",
    "Ese precio que se paga es el surgimiento de variables aleatorias íntimamente relacionadas con las gaussianas y que no nacen de manera natural como las variables que hemos estudiado (por ejemplo, la Poissot o la geométrica); es decir, son variables aleatorias que no se presentan en la naturaleza, de modo que son mas bien artificiales, pero su incorporación a la Estadística, tanto en teoría como en la práctica, ayudan a resolver una gran variedad de problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V.A. Chi cuadrada ($\\chi^2$)\n",
    "\n",
    "Si $X_1,X_2,...,X_k$ son $k$ gaussianas estándar independientes y $X=X_1^2+X_2^2+...+X_k^2$, se dice que $X$ es una variable aleatoria **chi cuadrada** con $k$ grados de libertad y se denota por $$X\\sim\\chi^2(k)$$ \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Sean $X_1,X_2,...,X_k$ algunas $k$ gaussianas independientes con media $\\mu$ y varianza $\\sigma^2$; $\\overline{X}=\\frac{X_1+X_2+...+X_k}{k}$ y $S=\\sqrt{\\frac{(X_1-\\overline{X})^2+(X_2-\\overline{X})^2+...+(X_k-\\overline{X})^2}{k-1}}$  \n",
    "\n",
    "$$\\frac{k-1}{\\sigma^2}S^2\\sim\\chi^2(k-1)$$\n",
    "\n",
    "**Demostración (para quien le interese)**\n",
    "\n",
    "$$\\frac{k-1}{\\sigma^2}S^2=\\frac{(X_1-\\overline{X})^2+(X_2-\\overline{X})^2+...+(X_k-\\overline{X})^2}{\\sigma^2}=\\left(\\frac{X_1-\\overline{X}}{\\sigma}\\right)^2+...+\\left(\\frac{X_k-\\overline{X}}{\\sigma}\\right)^2$$ y aplica cierta transformación para utilizar el Teorema de Cochran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V.A. t de Student\n",
    "\n",
    "Supongamos que $Z$ es una gaussiana estándar y $V$ es una $\\chi^2(k)$, siendo ambas independientes. Sea $T=\\frac{Z}{\\sqrt{V/k}}$.\n",
    "\n",
    "Se dice que $T$ es una variable aleatoria **t de Student** con $k$ grados de libertad y se denota por \n",
    "\n",
    "$$T\\sim t(k)$$\n",
    "\n",
    "**Ejemplo.**\n",
    "\n",
    "Sean $X_1,X_2,...,X_n$ algunas $n$ gaussianas independientes con media $\\mu$ y varianza $\\sigma^2$; $\\overline{X}=\\frac{X_1+X_2+...+X_n}{n}$ y $S=\\sqrt{\\frac{(X_1-\\overline{X})^2+(X_2-\\overline{X})^2+...+(X_n-\\overline{X})^2}{n-1}}$  \n",
    "\n",
    "Entonces $\\overline{X}\\sim\\mathrm{N}\\left(\\mu,\\frac{\\sigma^2}{n}\\right)$, de donde $\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}\\sim\\mathrm{N}(0,1)$; además $\\frac{k-1}{\\sigma^2}S^2\\sim\\chi^2(n-1)$.\n",
    "\n",
    "Se puede verificar que esta gaussiana estándar y esta chi-cuadrada son independientes.\n",
    "\n",
    "Ahora, tomemos $Z=\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}$ y $V=\\frac{n-1}{\\sigma^2}S^2$. Entonces $\\frac{Z}{\\sqrt{V/(n-1)}}$ es una $t(n-1)$.\n",
    "\n",
    "Pero \n",
    "\n",
    "$$\\frac{Z}{\\sqrt{V/(n-1)}}=\\frac{\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}}{\\sqrt{\\frac{(n-1)S^2}{\\sigma^2(n-1)}}}=\\frac{\\overline{X}-\\mu}{S/\\sqrt{n}}$$\n",
    "\n",
    "Nota que de todos los símbolos que intervienen en la última expresión, el único que no puedes calcular es $\\mu$. Por lo tanto esta expresión se utiliza para construir *intervalos de confianza* con el fin de estimar la media poblacional cuando se desconoce la varianza poblacional de la caraterística $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teorema del límite central\n",
    "\n",
    "Ya hemos insistido algunas de las razones por las cuales las gaussianas son las v.a. mas importantes. A continuación presentamos una más:\n",
    "\n",
    "**Teorema del límite central**\n",
    "\n",
    "Si $X_1,X_2,...,$ son variables aleatorias independientes e idénticamente distribuídas, con $E[X_i]=\\mu$ y $Var(X_i)=\\sigma^2$ (es decir, todas tienen la misma media y la misma varianza), y $X_{r_1},X_{r_2},...,X_{r_n}$ es una muestra cualquiera, entonces para $n$ grande, se tiene que el promedio es aproximadamente $\\mathrm{N}\\left(\\mu,\\frac{\\sigma^2}{n}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este resultado tiene implicaciones **importantísimas** en Estadística.\n",
    "\n",
    "Supongamos, por ejemplo, que quieres hacer inferencia sobre una característica $X$ de una población; por ejemplo, quieres saber el valor promedio $\\mu$ de esa característica.\n",
    "\n",
    "Toma una muestra aleatoria $X_1,X_2,...,X_n$ de la característa (es decir, toma una muestra de $n$ individuos y mide la característica $X$ en cada uno de ellos).\n",
    "\n",
    "El Teorema del Límite Central te dice que, sin importar cómo sea la característica, si $n$ es grande, tendrás que el número $\\frac{X_1+X_2+...+X_n}{n}$ *es casi* una $\\mathrm{N}\\left(\\mu,\\frac{\\sigma^2}{n}\\right)$. \n",
    "\n",
    "Por lo tanto $\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}$ *es muy parecida* a $\\mathrm{N}(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_param = 1.5\n",
    "\n",
    "# Generar muestra de tamaño 1,000,000\n",
    "exponencial = pd.DataFrame({\"valores\" : np.random.exponential(scale=1/lambda_param, size=1000000)})\n",
    "ggplot(exponencial) + geom_histogram(mapping=aes(x=\"valores\"),fill=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestras_exponenciales = [pd.DataFrame({f\"muestra_{x+1}\":exponencial[\"valores\"].sample(50,replace=True).values.tolist()}) \n",
    "                          for x in range(5000)]\n",
    "muestras_exp = pd.concat(muestras_exponenciales,axis=1)\n",
    "muestras_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias_muestrales = pd.DataFrame({\"medias\":muestras_exp.mean()})\n",
    "\n",
    "ggplot(data=medias_muestrales) + geom_histogram(mapping=aes(x=\"medias\"),fill=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sismos = pd.read_csv(\"C:\\\\Users\\\\Usuario\\\\Documents\\\\scidata\\\\24_inf_est\\\\proyectos\\\\sismos\\\\SSNMX_catalogo_19000101_20241206.csv\")\n",
    "sismos\n",
    "ggplot(sismos) + geom_histogram(mapping=aes(x=\"Profundidad\"),fill=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestras_sismos = [pd.DataFrame({f\"muestra_{x+1}\":sismos[\"Profundidad\"].sample(150,replace=True).values.tolist()}) \n",
    "                          for x in range(1000)]\n",
    "muestras_sism = pd.concat(muestras_sismos,axis=1)\n",
    "muestras_sism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias_muestrales = pd.DataFrame({\"medias\":muestras_sism.mean()})\n",
    "\n",
    "ggplot(data=medias_muestrales) + geom_histogram(mapping=aes(x=\"medias\"),fill=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sismos[\"Profundidad\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edades = pd.read_csv(\"C:\\\\Users\\\\Usuario\\\\Documents\\\\scidata\\\\24_inf_est\\\\proyectos\\\\calificaciones\\\\edades.csv\")\n",
    "edades\n",
    "ggplot(edades) + geom_histogram(mapping=aes(x=\"edad\"),fill=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestras_edades = [pd.DataFrame({f\"muestra_{x+1}\":edades[\"edad\"].sample(40,replace=True).values.tolist()}) \n",
    "                          for x in range(1000)]\n",
    "muestras_edades = pd.concat(muestras_edades,axis=1)\n",
    "muestras_edades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medias_muestrales = pd.DataFrame({\"medias\":muestras_edades.mean()})\n",
    "\n",
    "ggplot(data=medias_muestrales) + geom_histogram(mapping=aes(x=\"medias\"),fill=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edades[\"edad\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
