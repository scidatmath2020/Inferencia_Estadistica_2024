{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c109839-76e5-4452-880f-299ca738e9b6",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f853a67-22f5-4ca1-a4ef-1c5399fbe889",
   "metadata": {},
   "source": [
    "# Resumen de regresión lineal\n",
    "\n",
    "En nuestro repositorio de scripts encontrarás el script [linear_reg_function.py](https://github.com/scidatmath2020/Inferencia_Estadistica_2024/blob/main/scripts/linear_reg_function.py) que es donde se han programado todos los pasos para nuestra regresión. Se sugiere utilizar el siguiente preámbulo de trabajo:\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "import os\n",
    "ruta_funcion = # ruta donde descargaste la función\n",
    "os.chdir(ruta_funcion)\n",
    "from linear_reg_function import *\n",
    "\n",
    "####################################################################\n",
    "\n",
    "ruta_tabla = # ruta donde está tu tabla\n",
    "os.chdir(ruta_tabla)\n",
    "\n",
    "data = pd.read_csv(ruta_tabla)\n",
    "Y = #nombre de la columna objetivo\n",
    "predictores = #lista de nombres de las columnas predictoras\n",
    "\n",
    "################################################################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b3c86-8f70-4937-9472-10c5e1fb8b3d",
   "metadata": {},
   "source": [
    "## Planteamiento del modelo\n",
    "\n",
    "### Paso 1. Establecer el modelo\n",
    "Decidimos si trabajar con algunas columnas de la tabla o con el modelo con menor Índice de Akaike.\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "mi_regresion = linear_regression(data,Y,predictores,best_ml = True)\n",
    "\n",
    "################################################################\n",
    "```\n",
    "\n",
    "donde\n",
    "\n",
    "- ``best_ml=True`` indica que se buscará el modelo con menor índice de Akaike de entre todos los modelos posibles que se pueden establecer con las columnas ``predictores``; y ``best_ml=False`` indica que se trabajará con exactamente las columnas ``predictores`` y no se buscará el mejor modelo\n",
    "\n",
    "### Construcción del modelo\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "claves = [\n",
    "    \"modelo\", \"parametros\", \"intervalos_de_confianza\", \"r2\", \"r2_adj\", \"AIC\",\n",
    "    \"residuos\", \"residuos_qq\", \"residuos_histograma\", \"gaussianidad_residuos\",\n",
    "    \"homocedasticidad_grafica\", \"bp_p_value\", \"resultado_bptest\", \"dw_stat\",\n",
    "    \"resultado_dw\", \"p_value_tukey\", \"resultado_pval_tukey\", \n",
    "    \"residuos_parciales_grafica\", \"indices_alto_leverage\", \n",
    "    \"indices_outliers_significativos\", \"indices_alta_influencia\", \"predictores\"\n",
    "]\n",
    "\n",
    "resultado = dict(zip(claves, mi_regresion))\n",
    "\n",
    "################################################################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b4dd7-94a6-4c17-9a33-faca27a4100e",
   "metadata": {},
   "source": [
    "### Paso 2. Información de los parámetros del modelo.\n",
    "\n",
    "Encontrar los valores estimados $b_0$, $b_1$,...,$b_k$ con sus intervalos de confianza y p-valores de significancia:\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "resultado[\"parametros\"]  # da los coeficientes b_i\n",
    "\n",
    "################################################################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39c23c-6d90-4f7e-affe-90e8a8b25386",
   "metadata": {},
   "source": [
    "### Paso 3. Calificación del modelo.\n",
    "\n",
    "Encontrar los valores $R^2$, $R^2$ ajustado y el Índice de Akaike\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "resultado[\"r2\"]  # da el valor de R2\n",
    "resultado[\"r2_adj\"] # da el valor de R2 ajustado\n",
    "resultado[\"AIC\"] # da el valor del Índice de Akaike\n",
    "\n",
    "################################################################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e06b73-9b13-445f-9c0a-b2c982906be4",
   "metadata": {},
   "source": [
    "## Diagnósticos de la regresión\n",
    "\n",
    "### Paso 4.  Verificamos la normalidad de los residuos\n",
    "\n",
    "Se aplican las pruebas de gaussianidad a los residuos\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "resultado[\"residuos\"]  # devuelve los residuos\n",
    "resultado[\"residuos_qq\"] # devuelve el QQ-plot de los residuos\n",
    "resultado[\"residuos_histograma\"] # devulve el histograma de los residuos\n",
    "resultado[\"gaussianidad_residuos\"] # devuelve el resultado de las pruebas de gaussianidad a los residuos\n",
    "\n",
    "################################################################\n",
    "```\n",
    "\n",
    "**Reglas de decisión**\n",
    "\n",
    "$p$-valor|Decisión|Significado\n",
    ":--|:--|:--\n",
    "Pequeño|Rechazar $H_0$|Hay buena probabilidad de que **NO es gaussiana**\n",
    "Grande|Rechazar $H_1$|Hay buena probabilidad de que **SÍ es gaussiana**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98812c-dc46-422e-9198-5768bf461111",
   "metadata": {},
   "source": [
    "### Paso 5. Homocedasticidad de los residuos: Test de Breuch-Pagan\n",
    "\n",
    "Se aplica la prueba de Breuch-Pagan al modelo.\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "resultado[\"homocedasticidad_grafica\"] #devuelve el gráfico de la homocedasticidad\n",
    "resultado[\"bp_p_value\"] # devuelve el p-valor de la prueba de Breuch-Pagan\n",
    "resultado[\"resultado_bptest\"] # indica si hay o no homocedasticidad\n",
    "\n",
    "################################################################\n",
    "```\n",
    "\n",
    "**Regla de decisión.** Observar un cielo estrellado en el gráfico de homocedasticidad y  \n",
    "\n",
    "$p$-valor|Decisión|Significado\n",
    ":--|:--|:--\n",
    "Pequeño|Rechazar $H_0$|Hay buena probabilidad de que los residuos **NO sean homocedásticos**\n",
    "Grande|Rechazar $H_1$|Hay buena probabilidad de que los residuos **SÍ sean homocedásticos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce63398-37fe-4f64-a85e-4ecc25fe8361",
   "metadata": {},
   "source": [
    "### Paso 6. Residuos no correlacionados (independientes): Test de Durbin-Watson\n",
    "\n",
    "Se aplica la prueba de Durbin-Watson al modelo.\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "resultado[\"dw_stat\"] # devuelve el estadístico de la prueba de Durbin-Watson\n",
    "resultado[\"resultado_dw\"] # indica si hay o no incorrelación de los residuos\n",
    "\n",
    "################################################################\n",
    "```\n",
    "\n",
    "**Regla de decisión**\n",
    "\n",
    "$p$-valor|Decisión|Significado\n",
    ":--|:--|:--\n",
    "Pequeño|Rechazar $H_0$|Hay buena probabilidad de que los residuos **SÍ tengan autocorrelación**\n",
    "Grande|Rechazar $H_1$|Hay buena probabilidad de que los residuos **NO tengan autocorrelación**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f2cc7-93c7-48fe-92b5-2eef67f19765",
   "metadata": {},
   "source": [
    "### Paso 7. Aditividad del modelo: Test de Tukey\n",
    "\n",
    "Se aplica la prueba de Tukey al modelo\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "resultado[\"p_value_tukey\"] # devuelve el p-valor de la Prueba de Tukey\n",
    "resultado[\"resultado_pval_tukey\"] # indica si hay o no aditividad en el modelo\n",
    "\n",
    "################################################################\n",
    "```\n",
    "\n",
    "**Regla de decisión**\n",
    "\n",
    "$p$-valor|Decisión|Significado\n",
    ":--|:--|:--\n",
    "Pequeño|Rechazar $H_0$|Hay buena probabilidad de que el modelo **NO es aditivo**\n",
    "Grande|Rechazar $H_1$|Hay buena probabilidad de que el modelo **SÍ es aditivo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fe82e9-6af3-423f-85b3-70febd210caa",
   "metadata": {},
   "source": [
    "### Paso 8. Linealidad del modelo\n",
    "\n",
    "Se muestran las gráficas de residuos parciales\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "resultado[\"residuos_parciales_grafica\"] # Se muestran las gráficas de residuos parciales\n",
    "\n",
    "################################################################\n",
    "```\n",
    "\n",
    "Los residuos parciales se dibujan contra los valores de  $x_j$  y se hace su recta de regresión.\n",
    "\n",
    "Si esta no se ajusta a la curva dada por una regresión no paramétrica suave (las variables independientes no están predeterminadas y se construyen con los datos), el modelo no es lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887f9b8-baa4-407d-ba27-fb2610cdc985",
   "metadata": {},
   "source": [
    "### Paso 9. Observaciones anómalas\n",
    "\n",
    "* **Leverages.** son observaciones con un valor anómalo de las variables de control. No tienen por qué afectar los coeficientes de la regresión.\n",
    "\n",
    "* **Outliers de regresión** son observaciones que tienen un valor anómalo de la variable $Y$, condicionado a los valores de sus variables independientes $X_i$. Tendrán un residuo muy alto pero no pueden afectar demasiado a los coeficientes de la regresión.\n",
    "\n",
    "* **Observaciones influyentes** son aquellas que tienen un leverage alto; son outliers de regresión y afectan fuertemente a la regresión.\n",
    "\n",
    "Obtenemos los índices de las observaciones anómalas \n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "resultados[\"indices_alto_leverage\"] # puntos de apalancamiento\n",
    "resultados[\"indices_indices_outliers_significativos\"] # puntos indices_outliers_significativos\n",
    "resultados[\"indices_alta_influencia\"] # puntos de alta influencia\n",
    "\n",
    "################################################################\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68152bf5-11fb-4e4c-9feb-2aa42e8356a7",
   "metadata": {},
   "source": [
    "## Intervalos de confianza y significancia\n",
    "\n",
    "Siempre es buena idea incluir los intervalos de confianza para los coeficientes $\\beta_i$ y sus significancias\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "resultado[\"intervalos_de_confianza\"]  # da los intervalos de confianza al 95%\n",
    "resultado[\"modelo\"].summary()  # resumen general del modelo\n",
    "\n",
    "################################################################\n",
    "```\n",
    "\n",
    "Descripción|$p$-valor|Significado\n",
    ":--|:--:|:--\n",
    "¿Algún coeficiente es diferente de cero?|$<0.05$|Vale la pena hacer la regresión\n",
    "¿Qué coeficientes no son cero?|$<0.05$|El coeficiente respectivo tiene efectos significativos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0daad-fbde-4152-885a-1dca89787045",
   "metadata": {},
   "source": [
    "## Predicciones\n",
    "\n",
    "### Paso 12.\n",
    "\n",
    "Supongamos que llegan los nuevos $j$ datos que no fueron parte de las observaciones de nuestra tabla original:\n",
    "\n",
    "$X_1$|$X_2$|...|$X_k$\n",
    ":--:|:--:|:--:|:--:\n",
    "$x_1^{(1)}$|$x_1^{(2)}$|...|$x_1^{(k)}$\n",
    "$x_2^{(1)}$|$x_2^{(2)}$|...|$x_2^{(k)}$\n",
    "...|...|...|...\n",
    "$x_j^{(1)}$|$x_j^{(2)}$|...|$x_j^{(k)}$\n",
    "\n",
    "Aquí, $x_{r}^{(s)}$ representa el valor de la característica $X_s$ del nuevo individuo $r$. \n",
    "\n",
    "Llama ``newdata`` a la tabla anterior. Es decir, la columna 1 son los valores de la característica $X_1$ en los nuevos individuos; la columna 2 son los valores de la característica $X_2$ en los nuevos individuos; etcétera. **Es importante que los nombres de las columnas coincidan con los nombres de las características las características**.\n",
    "\n",
    "```python\n",
    "################################################################\n",
    "########################    EN PYTHON    #######################\n",
    "################################################################\n",
    "\n",
    "new_data = # tabla de nuevos valores\n",
    "new_data = new_data[resultado[\"predictores\"]]\n",
    "new_data = sm.add_constant(new_data, has_constant='add')\n",
    "\n",
    "prediccion = resultado[\"modelo\"].get_prediction(new_data).summary_frame(alpha=0.05)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Intervalo de confianza:\")\n",
    "print(prediccion[['mean', 'mean_ci_lower', 'mean_ci_upper']])\n",
    "\n",
    "print(\"\\nIntervalo de predicción:\")\n",
    "print(prediccion[['mean', 'obs_ci_lower', 'obs_ci_upper']])\n",
    "\n",
    "################################################################\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
