{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a609faf-1755-440d-96aa-9fe6bfb16f42",
   "metadata": {},
   "source": [
    "![imagenes](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc35db-d075-47ef-a1f9-059118e5b7c6",
   "metadata": {},
   "source": [
    "# Pruebas de normalidad\n",
    "\n",
    "Frecuentemente nos encontramos frente al problema de reconocer si una muestra proviene de una población gaussiana.\n",
    "\n",
    "Aunque ya hemos visto ajuste de distribuciones, para el caso de gaussianas tenemos más métodos para establecer, con cierta probabilidad, si una muestra proviene realmente de una distribución normal. Estos métodos están basados en pruebas de hipótesis, donde la hipótesis nula tiene la forma \"la población es gaussiana\", en tanto que la alternativa es \"la población no es gaussiana\".\n",
    "\n",
    "De esta manera, a cada una de las pruebas se le asigna un estadístico de contraste con el cual se calcula un $p$-valor, de modo que podemos escribirlas así:\n",
    "\n",
    "$$\\left\\{\\begin{array}{l}H_0:\\mbox{ la población es gaussiana}\\\\H_1:\\mbox{ la población no es gaussiana}\\end{array}\\right.$$\n",
    "\n",
    "con regla de decisión:\n",
    "\n",
    "$p$-valor|Decisión|Significado\n",
    ":--|:--|:--\n",
    "Pequeño|Rechazar $H_0$|Hay buena probabilidad de que **NO es gaussiana**\n",
    "Grande|Rechazar $H_1$|Hay buena probabilidad de que **SÍ es gaussiana**\n",
    "\n",
    "En este capítulo estudiaremos cuatro contrastes que nos ayudan para este fin:\n",
    "\n",
    "1. **Prueba de Shapiro-Wilk**: Una de las pruebas más populares y potentes para detectar desviaciones de la normalidad, especialmente en muestras pequeñas.\n",
    "2. **Prueba de Kolmogorov-Smirnov**: Una prueba basada en la comparación entre la distribución empírica y la distribución normal teórica. \n",
    "3. **Prueba de Anderson-Darling**: Una extensión del contraste de Kolmogorov-Smirnov que da más peso a las colas de la distribución.\n",
    "4. **Prueba de Jarque-Bera**: Evalúa la normalidad basándose en los momentos estadísticos de asimetría y curtosis.\n",
    "\n",
    "## Contexto e importancia de las pruebas de normalidad\n",
    "\n",
    "En estadística, muchas pruebas y modelos (como ANOVA, regresión lineal, t de Student, entre otros) requieren que los datos sigan una distribución normal. Por ello, las pruebas de normalidad son un paso esencial para garantizar la validez de los resultados.\n",
    "\n",
    "Es importante considerar también que:\n",
    "\n",
    "- **Tamaños de muestra pequeños**: Las pruebas pueden tener poca potencia, y un histograma o gráfico Q-Q puede complementar la evaluación.\n",
    "- **Tamaños de muestra grandes**: Las pruebas tienden a detectar pequeñas desviaciones que pueden no ser prácticamente significativas.\n",
    "\n",
    "A continuación, describiremos cada prueba en detalle y veremos cómo implementarlas usando Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389960b-dc3a-4efe-a64b-85cf4ac97a42",
   "metadata": {},
   "source": [
    "Para esto, utilizaremos las siguientes muestras:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats, lognorm\n",
    "import random\n",
    "\n",
    "\n",
    "#generada con N(mu=3.5,sigma=2)\n",
    "small_gauss = [2.9267007, 2.5763093, 4.9931801, 0.6564296, 1.4377333, 7.6412183, 2.9204735] \n",
    "\n",
    "#generada con t(3)\n",
    "big_t = [-0.577103929579228, -0.0669625949987604, 0.123572935953355, -0.524985500797433, -1.23249669279686, 0.509597230395874, -0.729559305649031, -0.41684441016622, 1.28155478163868, 0.924508782035897, 0.827405247774813, 1.59785194962189, -1.47879497630707, -1.26201626124022, -0.0593983026205043, -0.178873361732746, 0.801185847793428, 0.333473064862654, 1.25186288055626, 2.35949695172828, -0.633493106081742, -1.05713142223298, 0.0212461334293823, 0.466063027431909, 0.0762121526958427, -0.843837287109611, -0.104022595760381, 5.78550093074697, 0.709799846598426, -0.0897824055310009, -0.999402655342385, 0.337761665033848, -0.0306307006025367, 1.47728344947859, -0.176164802725808, 0.690341335235668, -0.292183630229324, -0.844902899428558, -3.49551302890857, 1.43006662844371, 1.24850000914668, -0.180820066444685, -0.573485189819109, 0.349757398842014, -2.09754115696913, -0.352572352149588, -0.509125036161415, 0.712742491824159, 0.519051722042105, -3.00737218678664]\n",
    "\n",
    "#generada con N(mu=5,sigma=1)\n",
    "random.seed(2024)\n",
    "big_gauss = stats.norm(scale=1, loc=5).rvs(1000)\n",
    "\n",
    "# Tomado de https://webspace.ship.edu/pgmarr/Geo441/Lectures/Lec%205%20-%20Normality%20Testing.pdf\n",
    "densidades_mexico = {\n",
    "    'Region': [\n",
    "        'Ajuno', 'Angahuan', 'Arantepacua', 'Aranza', 'Charapan', 'Cheran',\n",
    "        'Cocucho', 'Comachuen', 'Corupo', 'Ihuatzio', 'Janitzio', 'Jaracuaro',\n",
    "        'Nahuatzen', 'Nurio', 'Paracho', 'Patzcuaro', 'Pichataro',\n",
    "        'Pomacuaran', 'Quinceo', 'Quiroga', 'San Felipe', 'San Lorenzo',\n",
    "        'Sevina', 'Tingambato', 'Turicuaro', 'Tzintzuntzan', 'Urapicho'\n",
    "    ],\n",
    "    'Population_Density': [\n",
    "        5.11, 5.15, 5.00, 4.13, 5.10, 5.22, 5.04, 5.25, 4.53, 5.74, 6.63, 5.73,\n",
    "        4.77, 6.06, 4.82, 4.98, 5.36, 4.96, 5.94, 5.01, 4.10, 4.69, 4.97, 5.01,\n",
    "        6.19, 4.67, 6.30\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Generada con lognorm con media e y desviación 0.5\n",
    "np.random.seed(1)\n",
    "mi_lognorm = lognorm.rvs(s=.5, scale=math.exp(1), size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f85f01-3898-4709-ac6b-38102f6be4aa",
   "metadata": {},
   "source": [
    "## 1. Prueba de Shapiro-Wilk\n",
    "\n",
    "La prueba de Shapiro-Wilk evalúa si una muestra sigue una distribución normal al calcular un estadístico $W$ basado en el orden de los datos. Funiona bien para tamaños tan bajos como muestras de tamaño 3.\n",
    "\n",
    "### Implementación en Python\n",
    "\n",
    "Usaremos la función `shapiro` de la biblioteca `scipy.stats`.\n",
    "\n",
    "```python\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Prueba de Shapiro-Wilk\n",
    "stat, p_value = shapiro(data)\n",
    "\n",
    "print(f\"Estadístico W: {stat:.4f}\")\n",
    "print(f\"p-valor: {p_value:.4f}\")\n",
    "\n",
    "# Regla de decisión\n",
    "if p_value < 0.05:\n",
    "    print(\"Rechazamos H0: La muestra no sigue una distribución normal\")\n",
    "else:\n",
    "    print(\"No podemos rechazar H0: La muestra sigue una distribución normal\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b84455-5b68-4964-98ad-f2c84ea54918",
   "metadata": {},
   "source": [
    "## 2. Prueba de Kolmogorov-Smirnov\n",
    "\n",
    "Esta prueba compara la distribución empírica de los datos con la distribución normal teórica.\n",
    "\n",
    "### Implementación en Python\n",
    "Usaremos la función ``kstest`` de ``scipy.stats``.\n",
    "\n",
    "```python\n",
    "from scipy.stats import kstest, norm\n",
    "\n",
    "# Prueba de Kolmogorov-Smirnov\n",
    "from statistics import mean, stdev\n",
    "stat, p_value = kstest(data, 'norm', args=(mean(data), stdev(data)))\n",
    "\n",
    "print(f\"Estadístico KS: {stat:.4f}\")\n",
    "print(f\"p-valor: {p_value:.4f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079c42b-b05d-45a3-968b-b2ee3db0f27f",
   "metadata": {},
   "source": [
    "## 3. Prueba de Anderson-Darling\n",
    "La prueba de Anderson-Darling ajusta el estadístico de Kolmogorov-Smirnov para dar más peso a las colas.\n",
    "\n",
    "### Implementación en Python\n",
    "Usaremos la función ``anderson`` de ``scipy.stats``.\n",
    "\n",
    "```python\n",
    "from scipy.stats import anderson\n",
    "\n",
    "# Prueba de Anderson-Darling\n",
    "result = anderson(data, dist='norm')\n",
    "\n",
    "print(f\"Estadístico A: {result.statistic:.4f}\")\n",
    "for i, sig in enumerate(result.significance_level):\n",
    "    print(f\"Nivel de significancia {sig}%: Valor crítico = {result.critical_values[i]:.4f}\")\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9fb66-0974-4ed6-bc0c-26715c611ec7",
   "metadata": {},
   "source": [
    "## 4. Prueba de Jarque-Bera\n",
    "Esta prueba evalúa la normalidad mediante los coeficientes de asimetría y curtosis.\n",
    "\n",
    "### Implementación en Python\n",
    "Usaremos la función ``jarque_bera`` de ``scipy.stats``.\n",
    "\n",
    "```python\n",
    "from scipy.stats import jarque_bera\n",
    "\n",
    "# Prueba de Jarque-Bera\n",
    "stat, p_value = jarque_bera(data)\n",
    "\n",
    "print(f\"Estadístico JB: {stat:.4f}\")\n",
    "print(f\"p-valor: {p_value:.4f}\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72505981-d521-47cd-b91f-01a6b60c6b8e",
   "metadata": {},
   "source": [
    "## Algunas consideraciones \n",
    "\n",
    "Las pruebas de normalidad deben interpretarse en contexto, especialmente considerando el tamaño de la muestra.\n",
    "\n",
    "- Las representaciones gráficas, como histogramas o diagramas Q-Q, son una herramienta valiosa complementaria.\n",
    "- Aunque estas pruebas nos ayudan a evaluar la normalidad, la robustez de muchos modelos estadísticos permite cierto grado de desviación sin afectar significativamente los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d085109-9c66-4204-b364-3b4019a65915",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "A continuación mostramos una tabla resumen de estos contrastes de normalidad. **Recuerda que para utilizarlos en Python requieres la biblioteca ``scipy.stats`` y/o ``statsmodels``**.\n",
    "\n",
    "Prueba|Abreviatura|Tamaño de<br> muestra|Desventaja|Estadístico|**Python**\n",
    ":--|:--:|:--:|:--|:--:|:--\n",
    "Shapiro-Wilk|SW|$n \\leq 5000$|Sensible a valores repetidos y colas|W|``shapiro()``\n",
    "Kolmogorov-Smirnov|KS|$n \\leq 1000$|Requiere especificar parámetros|D|``kstest()``\n",
    "Anderson-Darling|AD|$n \\leq 5000$|Menos eficiente en muestras grandes|A|``anderson()``\n",
    "Jarque-Bera|JB|$n \\geq 20$|Menos sensible a desviaciones pequeñas|JB|``jarque_bera()``\n",
    "\n",
    "En el script puedes encontrar nuestra función genérica para realizar este tipo de pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05daa0e2-1dd1-4066-a282-64c42c5bc374",
   "metadata": {},
   "source": [
    "## Consideraciones finales\n",
    "\n",
    "1. **Tamaño de muestra:**\n",
    "   - Las pruebas como **Shapiro-Wilk** y **Anderson-Darling** son ideales para tamaños de muestra pequeños a moderados (hasta 5000 observaciones).\n",
    "   - **Kolmogorov-Smirnov** se recomienda para tamaños pequeños a medianos (hasta 1000), ya que su eficiencia decrece con muestras grandes.\n",
    "   - **Jarque-Bera** es más confiable en tamaños de muestra grandes (n ≥ 20) debido a su dependencia de estadísticos como la asimetría y la curtosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e1319a-3d85-49e8-9797-2d13f0bbee98",
   "metadata": {},
   "source": [
    "2. **Repeticiones y valores atípicos:**\n",
    "   - Las pruebas como **Shapiro-Wilk** pueden verse afectadas por valores repetidos o extremos, lo que puede comprometer su capacidad para detectar normalidad.\n",
    "   - Gráficos complementarios como histogramas o diagramas Q-Q son útiles para identificar patrones visuales antes de realizar pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825d5ebf-0b82-411e-9dd9-ea94f1f60bca",
   "metadata": {},
   "source": [
    "3. **Colas de la distribución:**\n",
    "   - **Anderson-Darling** da mayor peso a las colas, lo que la hace especialmente útil si se sospechan problemas en los extremos de la distribución."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406cd39-a130-4ac4-aeab-7b298a5a546c",
   "metadata": {},
   "source": [
    "4. **Pruebas específicas vs. generales:**\n",
    "   - **Shapiro-Wilk** y **Anderson-Darling** están diseñadas exclusivamente para evaluar normalidad.\n",
    "   - **Jarque-Bera** es una prueba \"ómnibus\", útil si deseas evaluar otros momentos estadísticos (asimetría y curtosis) junto con la normalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99137e2a-6285-4fe1-a7fb-bd3f0e7aac1c",
   "metadata": {},
   "source": [
    "5. **Efecto del tamaño de muestra:**\n",
    "   - En muestras pequeñas, las pruebas de normalidad pueden tener poca potencia y no detectar desviaciones significativas.\n",
    "   - En muestras grandes, incluso pequeñas desviaciones de la normalidad pueden resultar en un rechazo de $H_0$, aunque estas desviaciones no sean prácticas ni relevantes para muchos análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44882d76-32e3-4228-b6d1-8fa6fd8f29f3",
   "metadata": {},
   "source": [
    "6. **Apoyo visual:**\n",
    "   - Complementar las pruebas estadísticas con visualizaciones como histogramas y diagramas Q-Q es una buena práctica para entender mejor los datos y confirmar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08b82a-f71d-4929-bef7-aafdd7a0589c",
   "metadata": {},
   "source": [
    "En conclusión, la elección de la prueba depende del tamaño de la muestra, las características de los datos y la naturaleza del análisis. Las representaciones gráficas son un valioso complemento a estas pruebas formales.\n",
    "\n",
    "## Comentario final\n",
    "\n",
    "Además de todo lo anteriormente dicho, también es importante mencionar que en muchas ocasiones es necesario realizar una transformación previa a los datos para obtener gaussianidad. Las transormaciones más usuales son logaritmo, raíz cuadrada y raíz cúbica:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "datos_log = np.log(datos)\n",
    "datos_sqrt = np.sqrt(datos)\n",
    "datos_sqrt3 = np.cbrt(datos)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
